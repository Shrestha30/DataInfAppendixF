argh==0.29.4
datasets==2.13.1
evaluate==0.4.0
numpy==1.24.4
numpy==1.25.2
pandas==2.0.3
peft==0.5.0
torch==2.0.1
tqdm==4.65.0
transformers==4.34.0.dev0


def get_grads_avg(X,y):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    X = torch.from_numpy(X).to(torch.float).to(device)
    y = torch.from_numpy(y).to(torch.float).to(device)

    grads = np.zeros((X.shape[0], 2))
    grads_second = np.zeros((X.shape[0], 2))

    loss_fn = torch.nn.BCELoss()

    for idx, (X_single, y_single) in enumerate(zip(X,y)):
        y_pred = model(X_single).reshape((y_single.shape))
        loss = loss_fn(y_pred, y_single)
        #optimizer.zero_grad()
        #loss.backward()
        #optimizer.step()
        #grads[idx] = model.linear3.weight.grad.cpu().numpy()

        first_drv = autograd.grad(loss, model.linear3.weight, create_graph=True)[0]
        second_drv_0 = autograd.grad(first_drv[0][0], model.linear3.weight, create_graph=True)[0]
        second_drv_1 = autograd.grad(first_drv[0][1], model.linear3.weight, create_graph=True)[0]

        grads[idx] = first_drv.cpu().detach().numpy()
        grads_second[idx] = np.array([second_drv_0.cpu().detach().numpy()[0][0], second_drv_1.cpu().detach().numpy()[0][1]])

    grad_dict = {i: {'main': None} for i in range(len(grads))}

    for i in range(len(grads)):
        grad_dict[i]['main'] = torch.from_numpy(grads[i])
    
    n = len(grad_dict.keys())
    
    grad_avg_dict={}
    for weight_name in grad_dict[0]:
        grad_avg_dict[weight_name]=torch.zeros(grad_dict[0][weight_name].shape)
        for val_id in grad_dict:
            grad_avg_dict[weight_name] += grad_dict[val_id][weight_name] / n

    return grad_avg_dict

def compute_grad_distances(grad_dict, grad_dict_avg):
    """
    Returns an array where each element is the distance of the 'main' gradient in grad_dict
    from the corresponding average gradient in grad_dict_avg.
    """
    distances = np.zeros(len(grad_dict))

    avg_vec = grad_dict_avg['main']  # assuming you're measuring only 'main'

    for i in grad_dict:
        diff = grad_dict[i]['main'] - avg_vec
        distances[i] = -torch.norm(diff).item()  # Euclidean norm

    return distances


    print("\nResults for Euclidean Distance Baseline\n")
    delete_pred_outliers_exp(args, data, euclidean_idxs)


    print("\nResults for Euclidean Distance Baseline\n")
    print(classification_report(gt_od_list, euclidean_list))

euclidean_idxs = find_idxs(compute_grad_distances(grads_dict, get_grads_avg(data.x_val, data.y_val)))
    euclidean_list = [1 if i in euclidean_idxs else 0 for i in range(data.x_train.shape[0])]
    print(sum(euclidean_list))



import matplotlib.pyplot as plt

    # Assuming these are your arrays
    grad_distances = compute_grad_distances(grads_dict, get_grads_avg(data.x_val, data.y_val))
    accurate_scores = inf_eng.IF_dict['accurate']

    # Sort indices based on ascending values of grad_distances
    sorted_indices = np.argsort(grad_distances)

    # Apply the sorted indices to both arrays
    grad_distances_sorted = grad_distances[sorted_indices]
    accurate_scores_sorted = accurate_scores[sorted_indices]


    # Create the plot
    plt.figure(figsize=(10, 5))
    plt.plot(grad_distances, color='blue', label='Gradient Distance')
    plt.plot(accurate_scores, color='red', label='Accurate Scores')

    plt.xlabel('Sample Index')
    plt.ylabel('Value')
    plt.title('Gradient Distance vs Accurate Scores')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    # plt.show()
    plt.savefig('gradient_vs_accurate.png', dpi=300)
